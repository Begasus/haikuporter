#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Copyright 2016-2021 Haiku, Inc. All rights reserved.
# Distributed under the terms of the MIT License.
#
# Authors:
#   Alexander von Gluck IV <kallisti5@unixzen.com>
#

import base64
import os
import sys
import json
import argparse
import paramiko

from io import StringIO

class color:
	HEADER = '\033[95m'
	OKBLUE = '\033[94m'
	OKGREEN = '\033[92m'
	WARNING = '\033[93m'
	FAIL = '\033[91m'
	ENDC = '\033[0m'
	BOLD = '\033[1m'
	UNDERLINE = '\033[4m'

def ssh_connect(args, data):
	ssh = paramiko.SSHClient()
	try:
		ssh.load_system_host_keys(os.path.join(args.confdir, "known_hosts"))
	except:
		print(color.FAIL + "FAIL: Invalid host key" + color.ENDC)
		return None

	jumpClient = None
	sshClient = None

	if 'jump' in data['ssh']:
		jumpClient=paramiko.SSHClient()
		jumpClient.load_host_keys(os.path.join(args.confdir, "known_hosts"))
		jPrivateKeyIO = StringIO(base64.b64decode(data['ssh']['jump']['privateKey']).decode("ascii"))
		jPrivateKey = paramiko.ed25519key.Ed25519Key.from_private_key(jPrivateKeyIO)
		jumpClient.connect(data['ssh']['jump']['host'],
			port=int(data['ssh']['jump']['port']),
			username=data['ssh']['jump']['user'],
			pkey=jPrivateKey,
			compress=True, allow_agent=False, look_for_keys=False,
			timeout=10)
	sshClient = paramiko.SSHClient()
	sshClient.load_host_keys(os.path.join(args.confdir, "known_hosts"))
	privateKeyIO = StringIO(base64.b64decode(data['ssh']['privateKey']).decode("ascii"))
	privateKey = paramiko.ed25519key.Ed25519Key.from_private_key(privateKeyIO)

	if jumpClient != None:
		transport=jumpClient.get_transport().open_channel(
			'direct-tcpip', (data['ssh']['host'],
				int(data['ssh']['port'])), ('', 0))
		sshClient.connect(hostname=data['ssh']['host'],
			port=int(data['ssh']['port']),
			username=data['ssh']['user'],
			pkey=privateKey,
			compress=True, allow_agent=False, look_for_keys=False,
			timeout=10, sock=transport)
	else:
		sshClient.connect(hostname=data['ssh']['host'],
			port=int(data['ssh']['port']),
			username=data['ssh']['user'],
			pkey=privateKey,
			compress=True, allow_agent=False, look_for_keys=False,
			timeout=10)

	sshClient.get_transport().set_keepalive(15)
	return sshClient

# Get state of cluster
def cluster_health(arguments):
	print(color.HEADER + "Name              + Host                        + Status" + color.ENDC)
	for filename in os.listdir(args.confdir):
		fullpath = os.path.join(args.confdir, filename)
		basename = os.path.basename(fullpath)
		extension = basename.split(".")
		if extension[-1] != 'json':
			continue
		with open(fullpath) as data_file:
			data = json.load(data_file)
		sys.stdout.write(extension[0].ljust(18))
		sys.stdout.write("| ")
		sys.stdout.write(data["ssh"]["host"].ljust(28))
		sys.stdout.write("| ")

		ssh = ssh_connect(args, data)
		if ssh is None:
			continue

		# All highly prone to messing up. yay.
		stdin, stdout, stderr = ssh.exec_command("uname -a")
		uname = stdout.readlines()[0].split()
		stdin, stdout, stderr = ssh.exec_command("nproc")
		cpus = stdout.readlines()[0].split()[0]

		print(color.OKGREEN + "Connected: " + uname[0] + " " + uname[3] + ". " + cpus + " " + uname[8] + " cores." + color.ENDC)
		ssh.close()

# Get provision nodes
def cluster_provision(arguments):
	print(color.HEADER + "Name              + Status" + color.ENDC)
	for filename in os.listdir(args.confdir):
		fullpath = os.path.join(args.confdir, filename)
		basename = os.path.basename(fullpath)
		extension = basename.split(".")
		if extension[-1] != 'json':
			continue
		with open(fullpath) as data_file:
			data = json.load(data_file)
		sys.stdout.write(extension[0].ljust(18))
		sys.stdout.write("| ")

		ssh = ssh_connect(args, data)
		if ssh is None:
			continue
		sftp = ssh.open_sftp()

		# All highly prone to messing up. yay.
		stdin, stdout, stderr = ssh.exec_command("finddir B_USER_SETTINGS_DIRECTORY")
		settings_dir = stdout.readlines()[-1].strip()

		### Make sure debug_server doesn't halt crashes
		debug_server = os.path.join(settings_dir, "system", "debug_server")
		sftp.mkdir(debug_server)
		with sftp.open(os.path.join(debug_server, "settings"), "wb") as output_file:
			output_file.write("default_action report".encode())

		### Ensure system uses network time... create an empty file which the update-time
		### launchd job checks for.
		with sftp.open(os.path.join(settings_dir, "networktime"), "wb") as output_file:
			output_file.write("".encode())

		### Tune kernel settings
		kernel_settings = os.path.join(settings_dir, "kernel", "drivers")

		# Don't KDL. #13321 would be better.
		command = "sed -i '/^#bluescreen false/s/^#//' " + os.path.join(kernel_settings, "kernel")
		stdin, stdout, stderr = ssh.exec_command(command)

		print(color.OKBLUE + "Complete" + color.ENDC)
		ssh.close()
	print("It may be necessary to reboot the buildslaves to pick up the changes.")
	print("This can be done with 'builderctl reboot'")

def cluster_reboot(arguments):
	print(color.HEADER + "Name              + Result" + color.ENDC)
	for filename in os.listdir(args.confdir):
		fullpath = os.path.join(args.confdir, filename)
		basename = os.path.basename(fullpath)
		extension = basename.split(".")
		if extension[-1] != 'json':
			continue
		with open(fullpath) as data_file:
			data = json.load(data_file)
		sys.stdout.write(extension[0].ljust(18))
		sys.stdout.write("| ")

		ssh = ssh_connect(args, data)
		if ssh is None:
			continue
		stdin, stdout, stderr = ssh.exec_command("shutdown -r && exit")
		print(color.FAIL + "Issued" + color.ENDC)
		ssh.close()

parser = argparse.ArgumentParser(description='List and test connections to builders')
parser.add_argument('-C', '--confdir', help='Builder config directory on local machine', required=False, default=os.path.join(os.getcwd(), "buildmaster/builders"))
parser.add_argument('action', help='[ health | provision | reboot ]')
args = parser.parse_args()

if not os.path.isdir(args.confdir):
	print("Error: Builder inventory not found!")
	print("Please change to haikuports directory before running this tool (or pass --confdir)!")
	sys.exit()

if args.action == "health":
	cluster_health(args)
elif args.action == "provision":
	cluster_provision(args)
elif args.action == "reboot":
	cluster_reboot(args)
else:
	parser.print_help()
